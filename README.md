## Assignment 2.1
### Summary
In the manual TF-IDF results, unique words like “star” and “satellite” get high scores, while common words like “the” have low scores across documents. CountVectorizer outputs simple term counts, making frequent words appear important regardless of meaning. TfidfVectorizer closely matches the manual TF-IDF patterns, giving high weights to rare, informative words and low weights to common ones, confirming consistency between the manual implementation and scikit-learn’s approach.


The significant differences in scores for common words like “the” arise because TF-IDF intentionally reduces the importance of words appearing in many documents by assigning them low inverse document frequency (IDF) values. This prevents frequent, non-discriminative words from overshadowing more meaningful terms when representing documents. CountVectorizer lacks this adjustment: it simply counts occurrences, so words that appear often — even if they’re trivial — can dominate the feature space. In contrast, TF-IDF methods (both manual and TfidfVectorizer) down-weight these ubiquitous words, ensuring that words truly specific to each document are emphasized in the final representation.