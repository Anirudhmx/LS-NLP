{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19bcf11a",
   "metadata": {},
   "source": [
    "## Assignment 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c93055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eac19915",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'the sun is a star',\n",
    "    'the moon is a satellite',\n",
    "    'the sun and moon are celestial bodies'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7908cbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['a', 'and', 'are', 'bodies', 'celestial', 'is', 'moon', 'satellite', 'star', 'sun', 'the']\n"
     ]
    }
   ],
   "source": [
    "tokenized_corpus = [sentence.lower().split() for sentence in corpus]\n",
    "\n",
    "vocab = sorted(set(word for sentence in tokenized_corpus for word in sentence))\n",
    "print(f\"Vocabulary: {vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18a76ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'a': 0.2, 'and': 0.0, 'are': 0.0, 'bodies': 0.0, 'celestial': 0.0, 'is': 0.2, 'moon': 0.0, 'satellite': 0.0, 'star': 0.2, 'sun': 0.2, 'the': 0.2}, {'a': 0.2, 'and': 0.0, 'are': 0.0, 'bodies': 0.0, 'celestial': 0.0, 'is': 0.2, 'moon': 0.2, 'satellite': 0.2, 'star': 0.0, 'sun': 0.0, 'the': 0.2}, {'a': 0.0, 'and': 0.14285714285714285, 'are': 0.14285714285714285, 'bodies': 0.14285714285714285, 'celestial': 0.14285714285714285, 'is': 0.0, 'moon': 0.14285714285714285, 'satellite': 0.0, 'star': 0.0, 'sun': 0.14285714285714285, 'the': 0.14285714285714285}]\n"
     ]
    }
   ],
   "source": [
    "tf = []\n",
    "for sentence in tokenized_corpus:\n",
    "    word_counts = {}\n",
    "    total_words = len(sentence)\n",
    "    for word in vocab:\n",
    "        word_counts[word] = sentence.count(word) / total_words\n",
    "    tf.append(word_counts)\n",
    "\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769cc331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Manual TF-IDF Results:\n",
      "\n",
      "Document 1:\n",
      "{'a': 0.2, 'and': 0.0, 'are': 0.0, 'bodies': 0.0, 'celestial': 0.0, 'is': 0.2, 'moon': 0.0, 'satellite': 0.0, 'star': 0.2810930216216329, 'sun': 0.2, 'the': 0.14246358550964383}\n",
      "\n",
      "Document 2:\n",
      "{'a': 0.2, 'and': 0.0, 'are': 0.0, 'bodies': 0.0, 'celestial': 0.0, 'is': 0.2, 'moon': 0.2, 'satellite': 0.2810930216216329, 'star': 0.0, 'sun': 0.0, 'the': 0.14246358550964383}\n",
      "\n",
      "Document 3:\n",
      "{'a': 0.0, 'and': 0.20078072972973776, 'are': 0.20078072972973776, 'bodies': 0.20078072972973776, 'celestial': 0.20078072972973776, 'is': 0.0, 'moon': 0.14285714285714285, 'satellite': 0.0, 'star': 0.0, 'sun': 0.14285714285714285, 'the': 0.10175970393545987}\n"
     ]
    }
   ],
   "source": [
    "N = len(tokenized_corpus)\n",
    "idf = {}\n",
    "\n",
    "for word in vocab:\n",
    "    df = sum(1 for sentence in tokenized_corpus if word in sentence)\n",
    "    idf[word] = math.log((N) / (1 + df)) + 1\n",
    "\n",
    "tfidf_manual = []\n",
    "for doc_tf in tf:\n",
    "    doc_tfidf = {}\n",
    "    for word in vocab:\n",
    "        doc_tfidf[word] = doc_tf[word] * idf[word]\n",
    "    tfidf_manual.append(doc_tfidf)\n",
    "\n",
    "\n",
    "print(\"\\nManual TF-IDF Results:\")\n",
    "for i, doc_tfidf in enumerate(tfidf_manual):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71109fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CountVectorizer Vocabulary: ['and' 'are' 'bodies' 'celestial' 'is' 'moon' 'satellite' 'star' 'sun'\n",
      " 'the']\n",
      "CountVectorizer Matrix:\n",
      " [[0 0 0 0 1 0 0 1 1 1]\n",
      " [0 0 0 0 1 1 1 0 0 1]\n",
      " [1 1 1 1 0 1 0 0 1 1]]\n",
      "\n",
      "TfidfVectorizer Vocabulary: ['and' 'are' 'bodies' 'celestial' 'is' 'moon' 'satellite' 'star' 'sun'\n",
      " 'the']\n",
      "TfidfVectorizer Matrix:\n",
      " [[0.         0.         0.         0.         0.4804584  0.\n",
      "  0.         0.63174505 0.4804584  0.37311881]\n",
      " [0.         0.         0.         0.         0.4804584  0.4804584\n",
      "  0.63174505 0.         0.         0.37311881]\n",
      " [0.4261835  0.4261835  0.4261835  0.4261835  0.         0.32412354\n",
      "  0.         0.         0.32412354 0.25171084]]\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "cv_matrix = cv.fit_transform(corpus)\n",
    "print(\"\\nCountVectorizer Vocabulary:\", cv.get_feature_names_out())\n",
    "print(\"CountVectorizer Matrix:\\n\", cv_matrix.toarray())\n",
    "\n",
    "tv = TfidfVectorizer()\n",
    "tv_matrix = tv.fit_transform(corpus)\n",
    "print(\"\\nTfidfVectorizer Vocabulary:\", tv.get_feature_names_out())\n",
    "print(\"TfidfVectorizer Matrix:\\n\", tv_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74cb2f3",
   "metadata": {},
   "source": [
    "## Assignment 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565d26cb",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b7f8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='latin-1')[['v1', 'v2']]\n",
    "df.columns = ['Label', 'Message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13feb223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                            Message\n",
       "0         0  Go until jurong point, crazy.. Available only ...\n",
       "1         0                      Ok lar... Joking wif u oni...\n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         0  U dun say so early hor... U c already then say...\n",
       "4         0  Nah I don't think he goes to usf, he lives aro...\n",
       "...     ...                                                ...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "5568      0              Will Ì_ b going to esplanade fr home?\n",
       "5569      0  Pity, * was in mood for that. So...any other s...\n",
       "5570      0  The guy did some bitching but I acted like i'd...\n",
       "5571      0                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "10b4f3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\AppData\\Local\\Temp\\ipykernel_21436\\2309508539.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df.iloc[0][1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99f27f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aniru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aniru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee61824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word2Vec model... (this may take a few minutes)\n",
      "Word2Vec loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained Word2Vec model\n",
    "print(\"Loading Word2Vec model... (this may take a few minutes)\")\n",
    "w2v_model = api.load(\"word2vec-google-news-300\")\n",
    "print(\"Word2Vec loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24ec8ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'] = df['Label'].map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461404ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "def text_to_vector(tokens, w2v, vector_size=300):\n",
    "    vectors = [w2v[word] for word in tokens if word in w2v]\n",
    "    if vectors:return np.mean(vectors, axis=0)\n",
    "        \n",
    "    else:\n",
    "        return np.zeros(vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efdc2a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vectors = np.vstack([text_to_vector(preprocess_text(msg), w2v_model) \n",
    "                       for msg in df['Message']])\n",
    "y = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a657741c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01980591,  0.05167062,  0.02709961,  0.21868025, -0.0310342 ,\n",
       "        0.03897967,  0.08196586, -0.09603446,  0.01432146,  0.07736329,\n",
       "       -0.06193366, -0.1637486 , -0.02575248, -0.0471889 , -0.10367257,\n",
       "        0.14072964,  0.15539551,  0.09352984,  0.03390067, -0.02132089,\n",
       "       -0.0716391 , -0.01377705,  0.09657506,  0.03925433, -0.01184082,\n",
       "        0.0204869 , -0.12768555,  0.02552141,  0.0472363 , -0.04317801,\n",
       "       -0.05688912,  0.02345221, -0.05597796, -0.01293073, -0.01777867,\n",
       "       -0.04088129, -0.02099078, -0.02489035,  0.02235821,  0.03364781,\n",
       "        0.03664725, -0.09109061,  0.13033621,  0.05961827,  0.02466256,\n",
       "       -0.08101545, -0.09543718, -0.05844443,  0.01415144,  0.10117885,\n",
       "       -0.0839059 ,  0.15156338, -0.02831377,  0.01769148, -0.05941882,\n",
       "        0.08585031, -0.09414673, -0.1260376 ,  0.04568917, -0.09597342,\n",
       "       -0.09876796,  0.047869  , -0.09463065, -0.06553432,  0.01525879,\n",
       "       -0.10970198, -0.07511684,  0.04650007, -0.01913779,  0.10336304,\n",
       "        0.07246617,  0.05862863,  0.10284424,  0.09385463, -0.0927372 ,\n",
       "       -0.0238266 , -0.02731991,  0.07695443, -0.02632468,  0.00917271,\n",
       "       -0.01315962, -0.00046199,  0.04807609, -0.0443246 ,  0.02019392,\n",
       "        0.03188651, -0.08818708,  0.12028939,  0.04601969, -0.01204136,\n",
       "        0.00496347,  0.0637643 , -0.04974801, -0.07066781, -0.04488264,\n",
       "       -0.04113552,  0.07529994,  0.08110701,  0.13564846, -0.03528377,\n",
       "       -0.10637992,  0.06903839, -0.05086844,  0.02253941, -0.07918876,\n",
       "        0.04702323, -0.06663295, -0.03565325,  0.04494585, -0.06889562,\n",
       "       -0.05538505, -0.04740252, -0.01196289, -0.01373073,  0.1101314 ,\n",
       "        0.00116839,  0.01028006, -0.09581648,  0.04957363, -0.03338623,\n",
       "       -0.00854492, -0.02211216, -0.02562005,  0.07173375,  0.07111304,\n",
       "       -0.06378392, -0.13410732, -0.06396593, -0.03100586,  0.06530762,\n",
       "       -0.09393311, -0.01925223,  0.0137983 ,  0.04153878, -0.07550049,\n",
       "       -0.00205776,  0.0098877 ,  0.02410017,  0.08930315,  0.07156372,\n",
       "        0.09906878, -0.0588902 ,  0.00262015, -0.00697545,  0.01809692,\n",
       "       -0.02730887, -0.08014788,  0.03264727, -0.03074428, -0.08626012,\n",
       "        0.08080183,  0.01949637, -0.10412598,  0.03011649, -0.05943516,\n",
       "       -0.10423061,  0.06842041,  0.03314209, -0.09398106, -0.08602251,\n",
       "       -0.02655465,  0.03639439,  0.02269636, -0.02308437,  0.02354431,\n",
       "       -0.12145124,  0.06025914, -0.07329886, -0.01035854, -0.02377755,\n",
       "       -0.16694424, -0.09872437,  0.03763798, -0.05874198, -0.04694476,\n",
       "        0.07421439,  0.11567034, -0.13160051,  0.02513559, -0.01504517,\n",
       "       -0.03160749, -0.0718907 ,  0.02052525, -0.05908203,  0.01804461,\n",
       "        0.00045667, -0.06809779, -0.02048383,  0.02173506, -0.00281688,\n",
       "        0.08375768,  0.04501397, -0.02994646,  0.0243127 ,  0.03759656,\n",
       "        0.03844997, -0.05371421,  0.00846209, -0.07454573, -0.07968576,\n",
       "        0.00110245,  0.04667446, -0.0745321 , -0.07763945,  0.07204764,\n",
       "       -0.01079886, -0.02583531, -0.03667777, -0.06471471,  0.1312343 ,\n",
       "        0.05860465,  0.10038539, -0.07864162,  0.05597796, -0.0692106 ,\n",
       "        0.01562064,  0.12547956,  0.00473663, -0.1137085 , -0.00459835,\n",
       "       -0.03782436,  0.05192784,  0.0216217 ,  0.01147025,  0.03968375,\n",
       "       -0.00990949,  0.01855033, -0.00765773,  0.00999682, -0.04847063,\n",
       "       -0.00174386, -0.10166277,  0.00409371,  0.08057512,  0.05312238,\n",
       "        0.01702881,  0.0239236 ,  0.02401297,  0.03279768,  0.07486398,\n",
       "        0.16401018,  0.06258719,  0.06491634, -0.052451  , -0.02000645,\n",
       "        0.02530343, -0.02405391,  0.07550049,  0.02864075, -0.09853908,\n",
       "        0.0798863 ,  0.07226127,  0.10417829,  0.11369105,  0.05357143,\n",
       "       -0.13286482, -0.04716274, -0.07140242, -0.07459586, -0.10782296,\n",
       "       -0.05622864, -0.00323486,  0.02403859, -0.04016113, -0.02911377,\n",
       "        0.02981131,  0.02340698, -0.01596505, -0.04670062,  0.02409581,\n",
       "       -0.04310172,  0.04452951,  0.00573295,  0.0149013 ,  0.14366804,\n",
       "       -0.02467128, -0.07754952, -0.11137172, -0.09494019,  0.07885129,\n",
       "       -0.03336007,  0.03865269, -0.0519104 , -0.00269863,  0.00087629,\n",
       "        0.0293214 , -0.01795305,  0.00688171, -0.00676618,  0.05931527,\n",
       "        0.00177002,  0.04244123, -0.11790248,  0.09221976,  0.00572859,\n",
       "       -0.03272356,  0.02765764, -0.07992554, -0.05235944,  0.03033665],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = preprocess_text(df['Message'][0])\n",
    "vectors = [w2v_model[word] for word in tokens if word in w2v_model]\n",
    "vectors\n",
    "np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e967f483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01980591,  0.05167062,  0.02709961,  0.21868025, -0.0310342 ,\n",
       "        0.03897967,  0.08196586, -0.09603446,  0.01432146,  0.07736329,\n",
       "       -0.06193366, -0.16374861, -0.02575248, -0.0471889 , -0.10367257,\n",
       "        0.14072964,  0.15539551,  0.09352984,  0.03390067, -0.02132089,\n",
       "       -0.0716391 , -0.01377705,  0.09657506,  0.03925433, -0.01184082,\n",
       "        0.0204869 , -0.12768555,  0.02552141,  0.0472363 , -0.04317801,\n",
       "       -0.05688912,  0.02345221, -0.05597796, -0.01293073, -0.01777867,\n",
       "       -0.04088129, -0.02099078, -0.02489035,  0.02235821,  0.03364781,\n",
       "        0.03664725, -0.09109061,  0.13033621,  0.05961827,  0.02466256,\n",
       "       -0.08101545, -0.09543718, -0.05844443,  0.01415144,  0.10117885,\n",
       "       -0.0839059 ,  0.15156338, -0.02831377,  0.01769148, -0.05941882,\n",
       "        0.08585031, -0.09414673, -0.1260376 ,  0.04568917, -0.09597342,\n",
       "       -0.09876796,  0.047869  , -0.09463065, -0.06553432,  0.01525879,\n",
       "       -0.10970198, -0.07511684,  0.04650007, -0.01913779,  0.10336304,\n",
       "        0.07246617,  0.05862863,  0.10284424,  0.09385463, -0.0927372 ,\n",
       "       -0.0238266 , -0.02731991,  0.07695443, -0.02632468,  0.00917271,\n",
       "       -0.01315962, -0.00046199,  0.04807609, -0.0443246 ,  0.02019392,\n",
       "        0.03188651, -0.08818708,  0.12028939,  0.04601969, -0.01204136,\n",
       "        0.00496347,  0.0637643 , -0.04974801, -0.07066781, -0.04488264,\n",
       "       -0.04113552,  0.07529994,  0.08110701,  0.13564846, -0.03528377,\n",
       "       -0.10637992,  0.06903839, -0.05086844,  0.02253941, -0.07918876,\n",
       "        0.04702323, -0.06663295, -0.03565325,  0.04494585, -0.06889562,\n",
       "       -0.05538505, -0.04740252, -0.01196289, -0.01373073,  0.1101314 ,\n",
       "        0.00116839,  0.01028006, -0.09581648,  0.04957363, -0.03338623,\n",
       "       -0.00854492, -0.02211216, -0.02562005,  0.07173375,  0.07111304,\n",
       "       -0.06378392, -0.13410732, -0.06396593, -0.03100586,  0.06530762,\n",
       "       -0.09393311, -0.01925223,  0.0137983 ,  0.04153878, -0.07550049,\n",
       "       -0.00205776,  0.0098877 ,  0.02410017,  0.08930315,  0.07156372,\n",
       "        0.09906878, -0.0588902 ,  0.00262015, -0.00697545,  0.01809692,\n",
       "       -0.02730887, -0.08014788,  0.03264727, -0.03074428, -0.08626012,\n",
       "        0.08080183,  0.01949637, -0.10412598,  0.03011649, -0.05943516,\n",
       "       -0.10423061,  0.06842041,  0.03314209, -0.09398106, -0.08602251,\n",
       "       -0.02655465,  0.03639439,  0.02269636, -0.02308437,  0.02354431,\n",
       "       -0.12145124,  0.06025914, -0.07329886, -0.01035854, -0.02377755,\n",
       "       -0.16694424, -0.09872437,  0.03763798, -0.05874198, -0.04694476,\n",
       "        0.07421439,  0.11567034, -0.13160051,  0.02513559, -0.01504517,\n",
       "       -0.03160749, -0.0718907 ,  0.02052525, -0.05908203,  0.01804461,\n",
       "        0.00045667, -0.06809779, -0.02048383,  0.02173506, -0.00281688,\n",
       "        0.08375768,  0.04501397, -0.02994646,  0.0243127 ,  0.03759656,\n",
       "        0.03844997, -0.05371421,  0.00846209, -0.07454573, -0.07968576,\n",
       "        0.00110245,  0.04667446, -0.0745321 , -0.07763945,  0.07204764,\n",
       "       -0.01079886, -0.02583531, -0.03667777, -0.06471471,  0.1312343 ,\n",
       "        0.05860465,  0.10038539, -0.07864162,  0.05597796, -0.0692106 ,\n",
       "        0.01562064,  0.12547956,  0.00473663, -0.1137085 , -0.00459835,\n",
       "       -0.03782436,  0.05192784,  0.0216217 ,  0.01147025,  0.03968375,\n",
       "       -0.00990949,  0.01855033, -0.00765773,  0.00999682, -0.04847063,\n",
       "       -0.00174386, -0.10166277,  0.00409371,  0.08057512,  0.05312238,\n",
       "        0.01702881,  0.0239236 ,  0.02401297,  0.03279768,  0.07486398,\n",
       "        0.16401018,  0.06258719,  0.06491634, -0.052451  , -0.02000645,\n",
       "        0.02530343, -0.02405391,  0.07550049,  0.02864075, -0.09853908,\n",
       "        0.0798863 ,  0.07226127,  0.10417829,  0.11369105,  0.05357143,\n",
       "       -0.13286482, -0.04716274, -0.07140242, -0.07459586, -0.10782296,\n",
       "       -0.05622864, -0.00323486,  0.02403859, -0.04016113, -0.02911377,\n",
       "        0.02981131,  0.02340698, -0.01596505, -0.04670062,  0.02409581,\n",
       "       -0.04310172,  0.04452951,  0.00573295,  0.0149013 ,  0.14366804,\n",
       "       -0.02467128, -0.07754952, -0.11137172, -0.09494019,  0.07885129,\n",
       "       -0.03336007,  0.03865269, -0.0519104 , -0.00269863,  0.00087629,\n",
       "        0.0293214 , -0.01795305,  0.00688171, -0.00676618,  0.05931527,\n",
       "        0.00177002,  0.04244123, -0.11790248,  0.09221976,  0.00572859,\n",
       "       -0.03272356,  0.02765764, -0.07992554, -0.05235944,  0.03033665])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8dfcb4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_vectors, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2396850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_message_class(model, w2v, message):\n",
    "    tokens = preprocess_text(message)\n",
    "    vec = text_to_vector(tokens, w2v).reshape(1, -1)\n",
    "    pred = model.predict(vec)[0]\n",
    "    return 'spam' if pred == 1 else 'ham'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d461dc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "print(predict_message_class(clf, w2v_model, \"click and claim reward now\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05330626",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68c2f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('Tweets.csv')[['airline_sentiment', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb83357",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_tweet(text):    \n",
    "    text = text.lower()\n",
    "    contractions = {\"don't\": \"do not\", \"can't\": \"cannot\", \"won't\": \"will not\"}\n",
    "    for k, v in contractions.items():\n",
    "        text = text.replace(k, v)\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)  # URLs\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)  # Mentions\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)  # Hashtags\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1d5bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vectors_2 = np.vstack([\n",
    "    text_to_vector(preprocess_tweet(tweet), w2v_model)\n",
    "    for tweet in df2['text']\n",
    "])\n",
    "y2 = df2['airline_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50a43bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    X_vectors_2, y2, test_size=0.2, random_state=42, stratify=y2)\n",
    "\n",
    "clf2 = LogisticRegression(max_iter=1000, multi_class='multinomial')\n",
    "clf2.fit(X_train2, y_train2)\n",
    "y_pred2 = clf2.predict(X_test2)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test2, y_pred2):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f327ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tweet_sentiment(model, w2v, tweet):\n",
    "    tokens = preprocess_tweet(tweet)\n",
    "    vec = text_to_vector(tokens, w2v).reshape(1, -1)\n",
    "    return model.predict(vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9523fad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative']\n"
     ]
    }
   ],
   "source": [
    "print(predict_tweet_sentiment(clf2, w2v_model, \"hated it\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b945b7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e5aaa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
